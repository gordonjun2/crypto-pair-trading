{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e43aa20",
   "metadata": {},
   "source": [
    "# Pairs Crash and Recovery Analysis\n",
    "\n",
    "In the dynamic world of financial markets, volatility is a constant companion, presenting both risks and opportunities for traders and investors. During periods of heightened volatility, understanding the relative performance of assets can provide valuable insights for making informed trading decisions. The Pairs Crash and Recovery Analysis aims to identify which assets experience the most significant crashes and recoveries, thereby revealing which assets demonstrate strength or weakness during turbulent times.\n",
    "\n",
    "Key Concepts:\n",
    "- **Crash**: A significant decline in the price of an asset within a short time period.\n",
    "- **Recovery**: A significant rebound in the price of an asset following a crash.\n",
    "- **Relative Performance**: Comparing the behavior of paired assets to determine which is stronger or weaker during periods of market stress.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "- **Identifying a Pair / Basket of Tokens**: Select a set of tokens that you want to analyze. These can be tokens with similar characteristics or those that are typically traded together.\n",
    "- **Defining Crash and Recovery Thresholds**: Set predefined percentage thresholds to determine what constitutes a large crash or recovery. For example, a 5% drop might be defined as a crash, and a 5% rise as a recovery.\n",
    "- **Calculating Percentage Changes**: Calculate the percentage change in closing prices from one period to the next for each token at selected intervals.\n",
    "- **Identifying Crashes and Recoveries**: Identify periods where the percentage change exceeds the defined thresholds for crashes and recoveries. This can be done using simple conditional logic applied to the percentage changes.\n",
    "- **Combining Consecutive Periods**: Combine consecutive periods that meet the crash or recovery criteria into single events. This step ensures that sustained trends are identified rather than isolated spikes.\n",
    "- **Comparing Performance**: Compare the performance of the tokens during identified crash and recovery periods to determine which asset is stronger or weaker. This can involve looking at the magnitude and duration of crashes and recoveries.\n",
    "\n",
    "In this notebook, the crash and recovery analysis is demonstrated using cryptocurrency price data sourced from the Binance, OKX, and Bybit APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab73ff6-fa1f-46cc-900b-8268a0c14305",
   "metadata": {},
   "source": [
    "## Prepare your Environment\n",
    "\n",
    "Ensure that the 'venv' kernel is selected for this notebook. If not, click on 'Kernel' at the top bar, select 'Change Kernel...' and select 'venv' as the kernel. For convenience, ensure that 'Always start the preferred kernel' is ticked. Click 'Select' to confirm the setting.\n",
    "\n",
    "Install the environment's dependencies using the command below. After installation, restart the kernel to use the updated packages. To restart, click on 'Kernel' at the top bar and select 'Restart Kernel' and click on 'Restart'. Please skip this step if you have already done it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d92236-023d-4e09-94c8-a65fcecd9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ad883-ce63-4504-8af6-52998aedb87d",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f89e4a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 29.034008,
     "end_time": "2023-11-01T02:04:18.534845",
     "exception": false,
     "start_time": "2023-11-01T02:03:49.500837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from utils import calculate_profit, plot_strategy\n",
    "from data_manager import load_ts_df, process_data, sanitize_data\n",
    "from typing import List\n",
    "import cvxpy as cvx\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0de13",
   "metadata": {},
   "source": [
    "## Process Price Dataframe\n",
    "\n",
    "- Before proceeding, ensure that the price data has been downloaded using ***'data_manager.py'***.\n",
    "- Enter the ***cex*** (Centralized Exchange) and ***interval*** values used for data download to load the relevant *.pkl* files and retrieve the dataframe.\n",
    "- You can specify a batch of pairs to load using the ***selected_pairs*** variable. The key represents the pair and its value represents the direction it must take (1: Long, -1: Short, 0: Does not matter). Unlike other notebooks, no pairs will be selected if the dictionary is empty.\n",
    "- Note that some pairs might be new and may lack sufficient data within the downloaded timeframe. Such pairs will be removed based on the ***nan_remove_threshold*** setting, which defines the maximum percentage of NaN values allowed relative to the total data points. For example, with a ***nan_remove_threshold*** of 0.1, if a pair has 100 data points and 15 are NaN, the pair will be excluded.\n",
    "- From the remaining pairs, you can filter the top N rolling or mean volume pairs using the ***top_n_volume_pairs*** and ***volume_filter_mode*** parameter. \n",
    "- This part of the code will also ensure that all timeseries columns have the same number of data points.\n",
    "- The earliest and latest dates for all pairs will be recorded. These dates can then be used to determine the timeframe for slicing the data in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13057dad-759b-4606-b673-6b699765f2c1",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffa57f5-0ef6-49ca-847f-b439c1c63bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "cex = 'binance'\n",
    "interval = '4h'\n",
    "nan_remove_threshold = 0.0\n",
    "\n",
    "# Select only the pairs below to analyse. All pairs will be selected if the list is empty.\n",
    "selected_pairs = []\n",
    "\n",
    "# Select only the top N mean volume pairs from the selected pairs to analyse.\n",
    "top_n_volume_pairs = 100\n",
    "\n",
    "# Select volume filter mode. Options: ['rolling', 'mean'].\n",
    "volume_filter_mode = 'rolling'\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa468df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode: Pairs-Trading (Beta Neutral) Strategy\n",
      "CEX: Binance\n",
      "Interval: 4h\n",
      "NaN Remove Threshold: 0.0\n",
      "Selected pairs to analyse: ['ALTUSDT', 'SOLUSDT', 'TRXUSDT', 'BTCUSDT']\n",
      "Top N Volume Pairs: 100\n",
      "Volume Filter Mode: Rolling\n",
      "Train-Test Split: False\n",
      "Rolling Window: 10\n",
      "Minimum Long Size (percentage of portfolio): 0.1\n",
      "Minimum Short Size (percentage of portfolio): 0.1\n",
      "Rolling Optimisation Unsolvable Threshold (percentage of available data): 0.05\n",
      "Successfully loaded candlestick dataframe for all available pairs.\n",
      "\n",
      "Earliest time series start date: 2024-02-18\n",
      "Latest time series end date: 2024-08-03\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMode: Pairs-Trading (Beta Neutral) Strategy\")\n",
    "print(\"CEX: {}\".format(str(cex).capitalize()))\n",
    "print(\"Interval: {}\".format(interval))\n",
    "print(\"NaN Remove Threshold: {}\".format(nan_remove_threshold))\n",
    "print(\"Selected pairs to analyse: {}\".format(selected_pairs))\n",
    "print(\"Top N Volume Pairs: {}\".format(top_n_volume_pairs))\n",
    "print(\"Volume Filter Mode: {}\".format(str(volume_filter_mode).capitalize()))\n",
    "\n",
    "merged_df = process_data('crash_recovery', cex, interval, nan_remove_threshold, selected_pairs,\n",
    "                 top_n_volume_pairs, volume_filter_mode)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66614d32-8464-4265-b709-8a2d7a681acf",
   "metadata": {},
   "source": [
    "## Sanitize the dataframe\n",
    "\n",
    "- Slice the dataframe according to the specified ***start_date*** and ***end_date***. Choose ***start_date*** and ***end_date*** within the timeframe shown by the output of the previous cell.\n",
    "- Interpolate any missing values in the dataframe.\n",
    "- If the interpolation fails, just backfill with the latest valid value.\n",
    "- Verify that all is as expected with an `assert` and check the shapes of 2 random pairs, which should have the same dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705815e-af19-428e-b1b2-2f1ffd123c1b",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b0551a-033f-4b9a-8ac0-d82ceef0861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "start_date = '2024-02-18' # refer to the previous output to set\n",
    "end_date = '2024-08-03' # refer to the previous output to set\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c499c5-4313-40e1-bb52-ae3462912b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-Data Check-\n",
      "BTCUSDT's Data Shape: (999, 1)\n",
      "SOLUSDT's Data Shape: (999, 1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "data_sanitized, sorted_available_pairs = sanitize_data(merged_df, start_date, end_date)\n",
    "\n",
    "if data_sanitized:\n",
    "    print(\"-Data Check-\")\n",
    "    keys = list(data_sanitized.keys())\n",
    "    count = 0\n",
    "\n",
    "    for key in keys:\n",
    "        print(\"{}'s Data Shape: {}\".format(key, data_sanitized[key].shape))\n",
    "        count+=1\n",
    "\n",
    "        if count == 2:\n",
    "            break\n",
    "            \n",
    "else:\n",
    "    print(\"No data found.\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a62a5",
   "metadata": {},
   "source": [
    "## Compute Percentage Returns\n",
    "\n",
    "To compute percentage returns with a time series of close data, you first need to calculate the daily returns by finding the percentage change between consecutive prices. This can be done using the formula below:\n",
    "$$Percentage \\space Return = \\frac{Price_{t} - Price_{t-1}}{Price_{t-1}} \\times 100$$\n",
    "1. ${Price_{t}}$ is the calculated price on day t.\n",
    "2. ${Price_{t-1}}$ is the calculated price on the previous candlestick.\n",
    "\n",
    "In a pandas DataFrame, this can be efficiently computed using the pct_change() method on the price column. The resulting series represents the daily percentage returns, reflecting the day-to-day performance of the asset. Summarizing or compounding these daily returns over longer periods can provide insights into the overall performance of the asset over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e53c419-c425-46da-8e69-c9087ef98586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-Data Check-\n",
      "Percentage Returns' Data Shape (should be 1 row lesser than printed above): (998, 4)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "returns = pd.DataFrame()\n",
    "\n",
    "for pair, df in data_sanitized.items():\n",
    "    tmp_return_df = df['Close'].pct_change().dropna().to_frame(name=pair)\n",
    "    returns = pd.merge(returns, tmp_return_df, how='outer', left_index=True, right_index=True)\n",
    "returns = returns.T.sort_index().T\n",
    "\n",
    "print(\"-Data Check-\")\n",
    "print(\"Percentage Returns' Data Shape (should be 1 row lesser than printed above): {}\".format(returns.shape))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e745b48a-b0e5-45f0-bdd6-7a045738364b",
   "metadata": {},
   "source": [
    "## Select Pairs for Detailed Analysis\n",
    "\n",
    "- Please select any pair combination from the output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9456fa-811f-4cfc-b2b3-80b8be59f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selectable pairs:\n",
      "- ALTUSDT\n",
      "- BTCUSDT\n",
      "- SOLUSDT\n",
      "- TRXUSDT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSelectable pairs:\")\n",
    "\n",
    "for pair in sorted_available_pairs:\n",
    "    print(\"- {}\".format(pair))\n",
    "\n",
    "sorted_available_pairs = {pair:selected_pairs[pair] for pair in sorted_available_pairs if pair in selected_pairs}\n",
    "\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.659839,
   "end_time": "2023-11-01T02:04:21.309361",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-01T02:03:46.649522",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
